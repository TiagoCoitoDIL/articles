# AWS re:Invent 2022 | Day 5 - Thursday, Dec. 1



## Dr. Werner Vogels Keynote

Great Keynote from Join Dr. Werner Vogels, Amazon.com VP and CTO.

The Keynote started with a funny video to demostrate that life and nature are asynchronous and parallel. 
He forced the idea that asynchronous is natural and synchronous is just an ilusion. It was a funny way to introduce us the theme of this Keynote that is asynchronous and event-driven architecture.

During the keynote has been announced new features on AWS Services.

The first one, [AWS Step Functions Distributed Map](https://aws.amazon.com/pt/blogs/aws/step-functions-distributed-map-a-serverless-solution-for-large-scale-parallel-data-processing/). 


[Step Functions](https://aws.amazon.com/step-functions/) are simple way to iterate objects through steps in an easy-to-use visual workflow. 
Now using this new mode "distributed map" we can run thousands of parallel workflows based on object updates in S3.  

![AWS Step Functions Distributed Map](../Images/AWS/day5/IMG_8761.jpeg)


*"All **complex systems** that work evolved from **simpler systems** that worked"*

Even event-driven architectures use simple components, we can actually make complex systems and it sometimes can look a little daunting if we have lot of components. To simplify and accelerate architecting, configuring, and building serverless applications, has been announced [AWS Application Composer](https://aws.amazon.com/about-aws/whats-new/2022/12/aws-application-composer-preview/?nc1=h_ls)  

We can drag, drop, and connect AWS services into an application architecture by using AWS Application Composer’s browser-based visual canvas. Looks like low-code for AWS services!

![AWS Application Composer](../Images/AWS/day5/IMG_8767.jpeg)


The power of using pipes is amazing in unix when we want to find some errors in a log file, we can sort and filter as we want, so follwing this approach, AWS has announced the addition of Amazon EventBridge Pipes [Amazon EventBridge Pipes](https://aws.amazon.com/about-aws/whats-new/2022/12/amazon-eventbridge-pipes-generally-available/)

![Amazon EventBridge Pipes](../Images/AWS/day5/IMG_8769.jpeg)

After this annoucement, Angela Timofte - Director of Engineering at Trustpilot, come up to the stage to give us an real world example of asychonry event-driven architecture.

![Trustpilot achitecture 1](../Images/AWS/day5/IMG_8770.jpeg)

![Trustpilot achitecture 2](../Images/AWS/day5/IMG_8771.jpeg)

They were "forced" to move to event-driven to dealing with the scale and growth of reviews on Trustpilot.

Back to the stage, Vogels started talking about the background architecture behind Amazon DynamoDB, and the patterns of asynchronous architecture. Those patterns can be found well-documented in the [Amazon Builders Library](https://aws.amazon.com/builders-library/?cards-body.sort-by=item.additionalFields.sortDate&cards-body.sort-order=desc&awsf.filter-content-category=*all&awsf.filter-content-type=*all&awsf.filter-content-level=*all).
Not just about patterns but also many articles and videos bout how Amazon builds and operates software can be found there.



To assist in managing that complexity in application stacks, AWS has announced [Amazon CodeCatalyst](https://aws.amazon.com/about-aws/whats-new/2022/12/announcing-amazon-codecatalyst-preview/). A unified software development service that makes it faster to build and deliver on AWS.  

![Amazon CodeCatalyst](../Images/AWS/day5/IMG_8775.jpeg)


Moving on, Vogels demonstrated how large data can become when trying to model reality. Simulations that incorporate real-life structures and patterns can become an incredibly useful tool in almost any situation. Highlighted at first by the Unreal demo, AWS announced AWS Ambit Scenario Designer.   

AWS Ambit Scenario Designer can render near-real-time 3D models and environments for use in simulations, training, and virtual walkthroughs. Models can use Unreal Engine 4 as well as OpenStreetMap data to generate environments.  


It's definitely a keynote to watch!

[See all here!](https://youtu.be/RfvL_423a-I?list=PL2yQDdvlhXf8xcKr0-BHEyg_8VB4tWdu1)


----

## Build a complete DevSecOps pipeline on AWS

George Rolston - Senior Solutions Architecture - Cloud Foundations AWS
Brian Terry - Senior PSA-ISV Integrations - CloudFormation AWS

![complete DevSecOps pipeline on AWS](../Images/AWS/day5/IMG_8790.jpeg)

In this workshop we learned how to build a DevSecOps CI/CD pipeline with security and compliance testing integrated into the development process. 

We used GitHub Actions to integrate [AWS CloudFormation Guard (cfn-guard)](https://docs.aws.amazon.com/cfn-guard/latest/ug/what-is-guard.html) to run policy validations and ensure that pipeline deployments are consistent and that they meet organization's compliance standards. More AWS for GitHub Actions can been found [here](https://github.com/aws-actions).

For the workshop, we followed a tutorial to create the three stages (build, compliance and deploy) for the pipeline in this Architecture.

![Architecture](../Images/AWS/day5/IMG_8802.jpeg)

 The result can be found [here](https://github.com/TiagoCoitoDIL/CompliantePipeline/tree/feat-init).

----

## Preserving and maximizing the value of digital media assets using Amazon S3


In this sessions we talk about 3 main points using S3 bucket

1 - Managing exponential growth
The data is all around us even in our pocket taking photo, Stream services and image how the content is beeing generated 

There are a mass of amount of data that we are alwauts using.
101zb of data created and replicated in the world in 2022.

There is a lot of data to store and we are alwats try to think how we should store them.

There are a lot of data, and most of the data is cold.. Mean we don't using so often. 


Many users com to s3 to manage their data.
Amazon s3 archival storage classes. -> ver imagem

Thre pupose glacier

S3 glacier instant retrieval - retrieve data that we are not using to often

S3 Glacier Flexible Retrieval - flexiblilty, 

S3 Glacier Deep Archive - truly cold data

2 - Preserving your most princeless assets

- Preserving, and sage the data

mostrar a image

S3 performs over 4 billion checksum computations per second, 


3 - Maximizing the value of archival data

1 PB restored every day from S3 Glacier


unlocking the potentail of your data


We have the opportunity to ear some example this use


->Warner Bros. Discovery https://wbd.com/

They start to digitization fisical films to be durable a long the years.

They innovate has they should store, but have to use AWS


thaking advantages of data the that has been perserved

-> CNN

-> PGA Tour https://www.pgatour.com/


[See all here!](https://youtu.be/8OI0Uu-YvD8)

----

## Accelerate high-performance workloads with Amazon File Cache

Darryl Osborne - Principal Solutions Architect, File Storage AWS
Mark Roper - Principal Software Engineer, Amazon File Cache AWS

![Amazon File Cache](../Images/AWS/day5/IMG_8855.jpeg)

This chalk talk started by introducing the [Amazon File Cache](https://aws.amazon.com/filecache/).

This service provides a high-speed cache on AWS to makes it easier to process file data, regardless of where the data is stored. 
It serves as a temporary, high-performance storage location for data that's stored in on-premises file systems, AWS file systems, and Amazon Simple Storage Service (Amazon S3) buckets.

To explain the purpose of this service they show us an example.

![Amazon File Cache](../Images/AWS/day5/IMG_8857.jpeg)

A compute cluster on AWS needs to access data locally for some workload, so typically compute on AWS will mount directly on local storage, but it creates some challenges because it has high latency and low network bandwidth. Whenever we want to access it will be slow.

What we could do is a bulk copy of on-premises data to AWS.
The problem is that in some cases it can be complicated and complex to move large amounts of data with a larger dataset and files in a complex directory structure, and of course it takes time to move everything to AWS.

So the solution is to Amazon File Cache, we will have a cache that automatically imports and temporarily stores data that's being used by the compute jobs on AWS.
When the data is in the cache the AWS compute cluster has access to that data at some millisecond latencies and up to hundreds of GB/s of throughput. 

![Amazon File Cache](../Images/AWS/day5/IMG_8861.jpeg)

Using File Cache connected to S3, it will act as a cache in front of S3 to have a high speed file system interface to process S3 datasets.

Because it was a chalk talk, there were so many questions regarding other kind of solutions for this example, using other services but the conclusion was everything depends of the customer needs and costs as a short or long term and Amazon File Cache is just a service that you can use.

This is an amazing service from AWS.
In many projects we may need to access to data on-premises and probably our first approach is to move everything to AWS S3 to reduce the time accessing to the files, but sometimes we don't need to move all the data for what we want to process, so using AWS file caching can be a good solution when we want to access on-premises data for a specific workload.

----

## re:Play party


What a party!! I felt like I was in a festival, so many people were around there!
We could understand the dimension of the event being in the party.

We were around 50 000 attendees for this conference, I am not sure if everybody was there but for sure we were so many.

![re:Play party](../Images/AWS/day5/re_play_party.gif)

The place was huge with two stages, one for DJs and one for live bands.
Two places to eat and interactive activities like dodgeball, Button Mash 4.0, archery tag and an entire area for Riot Games.

![re:Play party](../Images/AWS/day5/IMG_8883.jpeg)

![re:Play party](../Images/AWS/day5/IMG_8874.jpeg)

In the main stage we had a pleasure to have Martin Garrix playing for us.

![re:Play party](../Images/AWS/day5/MartinGarrix.png)

As I said, it was a festival and was amazing!! I enjoyed it a lot!!


----